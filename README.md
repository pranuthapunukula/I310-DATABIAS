# I310-DATABIAS
# The biases I believe may exist in the model based on my intuitions are the decreased accuracy for the scoring of comments that use non-explicit toxic language and the mislabeling of negative comments as threats or hate when theyâ€™re actually made in a self-directed or non-pejorative way. The biases I think may exist based on public documentation about how the model was created are an automatic higher scoring for terms used to describe marginalized groups even when not used negatively and certain terms holding the same negative value weight as others when not considered equivalent from a human-evaluated perspective. 
# 
